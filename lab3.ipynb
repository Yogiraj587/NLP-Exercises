{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lab 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total no. of characters in read dataset: 449945\n"
     ]
    }
   ],
   "source": [
    "file = open(\"rawCorpus.txt\", \"r\")\n",
    "rawReadCorpus = file.read()\n",
    "print (\"Total no. of characters in read dataset: {}\".format(len(rawReadCorpus)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "import string\n",
    "\n",
    "string.punctuation = string.punctuation +'“'+'”'+'-'+'’'+'‘'+'—'\n",
    "string.punctuation = string.punctuation.replace('.', '')\n",
    "\n",
    "file_new = \"\"\n",
    "for line in rawReadCorpus:\n",
    "    line_new = line.replace(\"\\n\", \"\")      \n",
    "    file_new += line_new\n",
    "preprocessedCorpus = \"\".join([char for char in file_new if char not in string.punctuation])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1st 5 sentences of preprocessed corpus are : \n",
      "[' no it was nt black monday  but while the new york stock exchange did nt fall apart friday as the dow jones industrial average plunged N points most of it in the final hour it barely managed to stay this side of chaos  some circuit breakers installed after the october N crash failed their first test traders say unable to cool the selling panic in both stocks and futures  the N stock specialist firms on the big board floor the buyers and sellers of last resort who were criticized after the N crash once again could nt handle the selling pressure  big investment banks refused to step up to the plate to support the beleaguered floor traders by buying big blocks of stock traders say  heavy selling of standard  poor s 500stock index futures in chicago unk beat stocks downward  seven big board stocks ual amr bankamerica walt disney capital citiesabc philip morris and pacific telesis group stopped trading and never resumed  the unk has already begun  the equity market was unk  once again the specialists were not able to handle the imbalances on the floor of the new york stock exchange said christopher unk senior vice president at unk securities corp  unk james unk chairman of specialists henderson brothers inc. it is easy to say the specialist is nt doing his job  when the dollar is in a unk even central banks ca nt stop it  speculators are calling for a degree of liquidity that is not there in the market  many money managers and some traders had already left their offices early friday afternoon on a warm autumn day because the stock market was so quiet  then in a unk plunge the dow jones industrials in barely an hour surrendered about a third of their gains this year unk up a 190.58point or N N loss on the day in unk trading volume  unk trading accelerated to N million shares a record for the big board  at the end of the day N million shares were traded  the dow jones industrials closed at N  the dow s decline was second in point terms only to the unk black monday crash that occurred oct. N N  in percentage terms however the dow s dive was the unk ever and the sharpest since the market fell N or N N a week after black monday  the dow fell N N on black monday  shares of ual the parent of united airlines were extremely active all day friday reacting to news and rumors about the proposed  N billion buyout of the airline by an unk group  wall street s takeoverstock speculators or risk arbitragers had placed unusually large bets that a takeover would succeed and ual stock would rise  at N p.m. edt came the unk news the big board was unk trading in ual pending news  on the exchange floor as soon as ual stopped trading we unk for a panic said one top floor trader  several traders could be seen shaking their heads when the news unk  for weeks the market had been nervous about takeovers after campeau corp. s cash crunch spurred concern about the prospects for future highly leveraged takeovers  and N minutes after the ual trading halt came news that the ual group could nt get financing for its bid  at this point the dow was down about N points  the market unk  arbitragers could nt dump their ual stock but they rid themselves of nearly every rumor stock they had  for example their selling caused trading halts to be declared in usair group which closed down N N to N N delta air lines which fell N N to N N and unk industries which sank N to N N  these stocks eventually reopened  but as panic spread speculators began to sell bluechip stocks such as philip morris and international business machines to offset their losses  when trading was halted in philip morris the stock was trading at N down N N while ibm closed N N lower at N  selling unk because of waves of automatic stoploss orders which are triggered by computer when prices fall to certain levels  most of the stock selling pressure came from wall street professionals including computerguided program traders  traders said most of their major institutional investors on the other hand sat tight  now at N one of the market s postcrash reforms took hold as the sp N futures contract had plunged N points equivalent to around a unk drop in the dow industrials  under an agreement signed by the big board and the chicago mercantile exchange trading was temporarily halted in chicago  after the trading halt in the sp N pit in chicago waves of selling continued to hit stocks themselves on the big board and specialists continued to unk prices down  as a result the link between the futures and stock markets unk apart  without the unk of stockindex futures the barometer of where traders think the overall stock market is headed many traders were afraid to trust stock prices quoted on the big board  the futures halt was even unk by big board floor traders  it unk things up said one major specialist  this confusion effectively halted one form of program trading stock index arbitrage that closely links the futures and stock markets and has been blamed by some for the market s big swings  in a stockindex arbitrage sell program traders buy or sell big baskets of stocks and offset the trade in futures to lock in a price difference  when the airline information came through it unk every model we had for the marketplace said a managing director at one of the largest programtrading firms  we did nt even get a chance to do the programs we wanted to do  but stocks kept falling  the dow industrials were down N points at N p.m. before the unk halt  at N p.m. at the end of the cooling off period the average was down N points  meanwhile during the the sp trading halt sp futures sell orders began unk up while stocks in new york kept falling sharply  big board chairman john j. phelan said yesterday the circuit breaker worked well unk  i just think it s unk at this point to get into a debate if index arbitrage would have helped or hurt things  under another postcrash system big board president richard unk mr. phelan was flying to unk as the market was falling was talking on an unk hot line to the other exchanges the securities and exchange commission and the federal reserve board  he unk out at a hightech unk center on the floor of the big board where he could watch unk on prices and pending stock orders  at about N p.m. edt sp futures resumed trading and for a brief time the futures and stock markets started to come back in line  buyers stepped in to the futures pit  but the unk of sp futures sell orders weighed on the market and the link with stocks began to fray again  at about N the sp market unk to still another limit of N points down and trading was locked again  futures traders say the sp was unk that the dow could fall as much as N points  during this time small investors began ringing their brokers wondering whether another crash had begun  at prudentialbache securities inc. which is trying to cater to small investors some unk brokers thought this would be the final unk  that s when george l. ball chairman of the prudential insurance co. of america unit took to the internal unk system to declare that the plunge was only mechanical  i have a unk that this particular decline today is something more unk about less  it would be my unk to advise clients not to sell to look for an opportunity to buy mr. ball told the brokers  at merrill lynch  co. the nation s biggest brokerage firm a news release was prepared unk merrill lynch comments on market drop  the release cautioned that there are significant differences between the current environment and that of october N and that there are still attractive investment opportunities in the stock market  however jeffrey b. lane president of shearson lehman hutton inc. said that friday s plunge is going to set back relations with customers because it unk the concern of volatility  and i think a lot of people will unk on program trading  it s going to bring the debate right back to the unk  as the dow average ground to its final N loss friday the sp pit stayed locked at its unk trading limit  jeffrey unk of program trader unk investment group said N sp contracts were for sale on the close the equivalent of  N million in stock  but there were no buyers  while friday s debacle involved mainly professional traders rather than investors it left the market vulnerable to continued selling this morning traders said  stockindex futures contracts settled at much lower prices than indexes of the stock market itself  at those levels stocks are set up to be unk by index arbitragers who lock in profits by buying futures when futures prices fall and simultaneously sell off stocks  but nobody knows at what level the futures and stocks will open today  the unk between the stock and futures markets friday will undoubtedly cause renewed debate about whether wall street is properly prepared for another crash situation  the big board s mr. unk said our unk performance was good  but the exchange will look at the performance of all specialists in all stocks  obviously we ll take a close look at any situation in which we think the unk obligations were nt met he said  see related story fed ready to unk big funds wsj oct. N N  but specialists complain privately that just as in the N crash the unk firms big investment banks that support the market by trading big blocks of stock stayed on the sidelines during friday s unk  mr. phelan said it will take another day or two to analyze who was buying and selling friday  concerning your sept. N pageone article on prince charles and the unk it s a few hundred years since england has been a kingdom  it s now the united kingdom of great britain and northern ireland unk unk northern ireland scotland and oh yes england too  just thought you d like to know  george unk  ports of call inc. reached agreements to sell its remaining seven aircraft to buyers that were nt disclosed  the agreements bring to a total of nine the number of planes the travel company has sold this year as part of a restructuring  the company said a portion of the  N million realized from the sales will be used to repay its bank debt and other obligations resulting from the currently suspended unk operations  earlier the company announced it would sell its aging fleet of boeing co. unk because of increasing maintenance costs  a consortium of private investors operating as unk funding co. said it has made a  N million cash bid for most of l.j.', 'hooker corp. s realestate and unk holdings  the  N million bid includes the assumption of an estimated  N million in secured liabilities on those properties according to those making the bid  the group is led by jay unk chief executive officer of unk investment corp. in unk and a. boyd simpson chief executive of the atlantabased simpson organization inc  mr. unk s company specializes in commercial realestate investment and claims to have  N billion in assets mr. simpson is a developer and a former senior executive of l.j.', 'hooker  the assets are good but they require more money and management than can be provided in l.j.', 'hooker s current situation said mr. simpson in an interview  hooker s philosophy was to build and sell  we want to build and hold  l.j.', 'hooker based in atlanta is operating with protection from its creditors under chapter N of the u.s. bankruptcy code  its parent company hooker corp. of sydney australia is currently being managed by a courtappointed provisional unk  sanford unk chief executive of l.j.']\n",
      "1st 5 words/tokens of preprocessed corpus are : \n",
      "['no', 'it', 'was', 'nt', 'black']\n"
     ]
    }
   ],
   "source": [
    "sentences = sent_tokenize(preprocessedCorpus)\n",
    "print(\"1st 5 sentences of preprocessed corpus are : \")\n",
    "print(sentences[0:5])\n",
    "words = word_tokenize(preprocessedCorpus)\n",
    "print(\"1st 5 words/tokens of preprocessed corpus are : \")\n",
    "print(words[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "filtered_tokens = [w for w in words if not w.lower() in stop_words]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Unigram, Bigram and Trigram Language Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample of n-grams:n-------------------------\n",
      "--> UNIGRAMS: n['no', 'it', 'was', 'nt', 'black'] ...n\n",
      "--> BIGRAMS: n[('no', 'it'), ('it', 'was'), ('was', 'nt'), ('nt', 'black'), ('black', 'monday')] ...n\n",
      "--> TRIGRAMS: n[('no', 'it', 'was'), ('it', 'was', 'nt'), ('was', 'nt', 'black'), ('nt', 'black', 'monday'), ('black', 'monday', 'but')] ...n\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from nltk.util import ngrams\n",
    "unigrams=[]\n",
    "bigrams=[]\n",
    "trigrams=[]\n",
    "for content in (sentences):\n",
    "    content = content.lower()\n",
    "    content = word_tokenize(content)\n",
    "    for word in content:\n",
    "        if (word =='.'):\n",
    "            content.remove(word) \n",
    "        else:\n",
    "            unigrams.append(word)\n",
    "    bigrams.extend(ngrams(content,2))\n",
    "\n",
    "    trigrams.extend(ngrams(content,3))\n",
    "print (\"Sample of n-grams:n\" + \"-------------------------\")\n",
    "print (\"--> UNIGRAMS: n\" + str(unigrams[:5]) + \" ...n\")\n",
    "print (\"--> BIGRAMS: n\" + str(bigrams[:5]) + \" ...n\")\n",
    "print (\"--> TRIGRAMS: n\" + str(trigrams[:5]) + \" ...n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample of n-grams after processing:n-------------------------\n",
      "--> UNIGRAMS: n['nt', 'black', 'monday', 'new', 'york'] ...n\n",
      "--> BIGRAMS: n[('was', 'nt'), ('nt', 'black'), ('black', 'monday'), ('monday', 'but'), ('the', 'new')] ...n\n",
      "--> TRIGRAMS: n[('it', 'was', 'nt'), ('was', 'nt', 'black'), ('nt', 'black', 'monday'), ('black', 'monday', 'but'), ('monday', 'but', 'while')] ...n\n"
     ]
    }
   ],
   "source": [
    "def stopwords_removal(n, a):     \n",
    "    b = []\n",
    "    if n == 1:\n",
    "        for word in a:\n",
    "            count = 0\n",
    "            if word in stop_words:\n",
    "                count = 0\n",
    "            else:\n",
    "                count = 1\n",
    "            if (count==1):\n",
    "                b.append(word)\n",
    "        return(b)\n",
    "    else:\n",
    "        for pair in a:\n",
    "            count = 0\n",
    "            for word in pair:\n",
    "                if word in stop_words:\n",
    "                    count = count or 0\n",
    "                else:\n",
    "                    count = count or 1\n",
    "            if (count==1):\n",
    "                b.append(pair)\n",
    "        return(b)\n",
    "unigrams_Processed = stopwords_removal(1,unigrams)\n",
    "bigrams_Processed = stopwords_removal(2,bigrams)\n",
    "trigrams_Processed = stopwords_removal(3,trigrams)\n",
    "print (\"Sample of n-grams after processing:n\" + \"-------------------------\")\n",
    "print (\"--> UNIGRAMS: n\" + str(unigrams_Processed[:5]) + \" ...n\")\n",
    "print (\"--> BIGRAMS: n\" + str(bigrams_Processed[:5]) + \" ...n\")\n",
    "print (\"--> TRIGRAMS: n\" + str(trigrams_Processed[:5]) + \" ...n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ngrams_freqDist(n, ngramList):\n",
    "    ngram_freq_dict = {}\n",
    "    for ngram in ngramList:\n",
    "        if ngram in ngram_freq_dict:\n",
    "            ngram_freq_dict[ngram] += 1\n",
    "        else:\n",
    "            ngram_freq_dict[ngram] = 1\n",
    "    return ngram_freq_dict\n",
    "    \n",
    "unigrams_freqDist = get_ngrams_freqDist(1, unigrams)\n",
    "unigrams_Processed_freqDist = get_ngrams_freqDist(1, unigrams_Processed)\n",
    "bigrams_freqDist = get_ngrams_freqDist(2, bigrams)\n",
    "bigrams_Processed_freqDist = get_ngrams_freqDist(2, bigrams_Processed)\n",
    "trigrams_freqDist = get_ngrams_freqDist(3, trigrams)\n",
    "trigrams_Processed_freqDist = get_ngrams_freqDist(3, trigrams_Processed)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting Next Three words using Bigram and Trigram Models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "smoothed_bigrams_probDist = {}\n",
    "V = len(unigrams_freqDist)\n",
    "for i in bigrams_freqDist:\n",
    "    smoothed_bigrams_probDist[i] = (bigrams_freqDist[i] + 1)/(unigrams_freqDist[i[0]]+V)\n",
    "smoothed_trigrams_probDist = {}\n",
    "for i in trigrams_freqDist:\n",
    "    smoothed_trigrams_probDist[i] = (trigrams_freqDist[i] + 1)/(bigrams_freqDist[i[0:2]]+V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "testSent1 = \"while friday 's debacle involved mainly professional traders rather than investors\"\n",
    "testSent2 = \"the stock and futures markets friday will undoubtedly cause renewed debate\"\n",
    "testSent3 = \"the sales will be used to repay its bank debt and other obligations\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 1:  {1: ('investors',), 2: ('than', 'investors')} Sentence 2:  {1: ('debate',), 2: ('renewed', 'debate')} Sentence 3:  {1: ('obligations',), 2: ('other', 'obligations')}\n"
     ]
    }
   ],
   "source": [
    "token_1 = word_tokenize(testSent1)\n",
    "token_2 = word_tokenize(testSent2)\n",
    "token_3 = word_tokenize(testSent3)\n",
    "ngram_1 = {1:[], 2:[]}    \n",
    "ngram_2 = {1:[], 2:[]}\n",
    "ngram_3 = {1:[], 2:[]}\n",
    "for i in range(2):\n",
    "    ngram_1[i+1] = list(ngrams(token_1, i+1))[-1]\n",
    "    ngram_2[i+1] = list(ngrams(token_2, i+1))[-1]\n",
    "    ngram_3[i+1] = list(ngrams(token_3, i+1))[-1]\n",
    "print(\"Sentence 1: \", ngram_1,\"Sentence 2: \",ngram_2,\"Sentence 3: \",ngram_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting next 3 possible word sequences with smoothed bigram model : \n",
      "1a)while friday 's debacle involved mainly professional traders rather than investors who was unk\n",
      "1b)while friday 's debacle involved mainly professional traders rather than investors should be unk\n",
      "2a)the stock and futures markets friday will undoubtedly cause renewed debate over the unk\n",
      "2b)the stock and futures markets friday will undoubtedly cause renewed debate if the unk\n",
      "3a)the sales will be used to repay its bank debt and other obligations were nt be\n",
      "3b)the sales will be used to repay its bank debt and other obligations resulting from the\n"
     ]
    }
   ],
   "source": [
    "def predict_next_word(last_word,probDist):\n",
    "    next_word = {}\n",
    "    for k in probDist:\n",
    "        if k[0] == last_word[0]:\n",
    "            next_word[k[1]] = probDist[k]\n",
    "    k = Counter(next_word)\n",
    "    high = k.most_common(1) \n",
    "    return high[0]\n",
    "\n",
    "def predict_next_3_words(token,probDist):\n",
    "    pred1 = []\n",
    "    pred2 = []\n",
    "    next_word = {}\n",
    "    for i in probDist:\n",
    "        if i[0] == token:\n",
    "            next_word[i[1]] = probDist[i]\n",
    "    k = Counter(next_word)\n",
    "    high = k.most_common(2)\n",
    "    w1a = high[0]\n",
    "    w1b = high[1]\n",
    "    w2a = predict_next_word(w1a,probDist)\n",
    "    w3a = predict_next_word(w2a,probDist)\n",
    "    w2b = predict_next_word(w1b,probDist)\n",
    "    w3b = predict_next_word(w2b,probDist)\n",
    "    pred1.append(w1a)\n",
    "    pred1.append(w2a)\n",
    "    pred1.append(w3a)\n",
    "    pred2.append(w1b)\n",
    "    pred2.append(w2b)\n",
    "    pred2.append(w3b)\n",
    "    return pred1,pred2\n",
    "\n",
    "print(\"Predicting next 3 possible word sequences with smoothed bigram model : \")\n",
    "pred1,pred2 = predict_next_3_words(ngram_1[1][0], smoothed_bigrams_probDist)\n",
    "print(\"1a)\" +testSent1 +\" \"+ pred1[0][0]+\" \"+pred1[1][0]+\" \"+pred1[2][0])\n",
    "print(\"1b)\" +testSent1 +\" \"+ pred2[0][0]+\" \"+pred2[1][0]+\" \"+pred2[2][0])\n",
    "pred1,pred2 = predict_next_3_words(ngram_2[1][0],smoothed_bigrams_probDist)\n",
    "print(\"2a)\" +testSent2 +\" \"+ pred1[0][0]+\" \"+pred1[1][0]+\" \"+pred1[2][0])\n",
    "print(\"2b)\" +testSent2 +\" \"+ pred2[0][0]+\" \"+pred2[1][0]+\" \"+pred2[2][0])\n",
    "pred1,pred2 = predict_next_3_words(ngram_3[1][0],smoothed_bigrams_probDist)\n",
    "print(\"3a)\" +testSent3 +\" \"+ pred1[0][0]+\" \"+pred1[1][0]+\" \"+pred1[2][0])\n",
    "print(\"3b)\" +testSent3 +\" \"+ pred2[0][0]+\" \"+pred2[1][0]+\" \"+pred2[2][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting next 3 possible word sequences with smoothed trigram model : \n",
      "1)while friday 's debacle involved mainly professional traders rather than investors it left the\n",
      "2)the stock and futures markets friday will undoubtedly cause renewed debate about whether wall\n",
      "3)the sales will be used to repay its bank debt and other obligations resulting from the\n"
     ]
    }
   ],
   "source": [
    "def predict_next_word(last_word,probDist):\n",
    "    next_word = {}\n",
    "    for k in probDist:\n",
    "        if k[0:2] == last_word:\n",
    "            next_word[k[2]] = probDist[k]\n",
    "    k = Counter(next_word)\n",
    "    high = k.most_common(1) \n",
    "    return high[0]\n",
    "def predict_next_3_words(token,probDist):\n",
    "    pred = []\n",
    "    next_word = {}\n",
    "    for i in probDist:\n",
    "        if i[0:2] == token:\n",
    "            next_word[i[2]] = probDist[i]\n",
    "    k = Counter(next_word)\n",
    "    high = k.most_common(2) \n",
    "    w1a = high[0]\n",
    "    tup = (token[1],w1a[0])\n",
    "    w2a = predict_next_word(tup,probDist)\n",
    "    tup = (w1a[0],w2a[0])\n",
    "    w3a = predict_next_word(tup,probDist)\n",
    "    pred.append(w1a)\n",
    "    pred.append(w2a)\n",
    "    pred.append(w3a)\n",
    "    return pred\n",
    "print(\"Predicting next 3 possible word sequences with smoothed trigram model : \")\n",
    "pred = predict_next_3_words(ngram_1[2],smoothed_trigrams_probDist)\n",
    "print(\"1)\" +testSent1 +\" \"+ pred[0][0]+\" \"+pred[1][0]+\" \"+pred[2][0])\n",
    "pred = predict_next_3_words(ngram_2[2],smoothed_trigrams_probDist)\n",
    "print(\"2)\" +testSent2 +\" \"+ pred[0][0]+\" \"+pred[1][0]+\" \"+pred[2][0])\n",
    "pred = predict_next_3_words(ngram_3[2],smoothed_trigrams_probDist)\n",
    "print(\"3)\" +testSent3 +\" \"+ pred[0][0]+\" \"+pred[1][0]+\" \"+pred[2][0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9 (tags/v3.7.9:13c94747c7, Aug 17 2020, 18:58:18) [MSC v.1900 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5109d816b82be14675a6b11f8e0f0d2e80f029176ed3710d54e125caa8520dfd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
